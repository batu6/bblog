---
title: "Random Variables, Distributions and CLT"
description: |
  We talk about CLT, sample size and SEM
preview: images/Ps_mean.png
author:
  - name: Batuhan Akçabozan
date: 2021-11-20
output:
  distill::distill_article:
    self_contained: false
    toc: true
    toc_depth: 3
bibliography: ../../references.bib 
csl: ../../apa.csl
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r}
library(plyr)
library(tidyverse)
library(cowplot)
library(tinytex)
```

## Editor's Notes / Corrections (05.12.21)

In the last paragraph of this post I discuss calculation of SEM with replicates and without replicates and I do some illustrations at the figures 6 and 7. I think they are conceptually correct but there are a few points that I must correct for. 

As I was trying to plot the flow cytometry data this weekend, I found myself thinking about sample size and replicates again. Ideally you can take mice and divide them into two groups like: control and treatment. Then each mouse is relatively random sampled. (Although they are technically inbred.). In my experiment, I divide cells from one mice into groups. Then I started thinking if comparing these cell groups with each other made sense, since technically they  come from same mouse. I thought they are also kind of dependent. But since we divide the cells randomly into groups, perhaps they are actually randomly sampled. But then again I do the same experiment couple of times and then I have data from other mice, which allows me to make broader conclusions. I guess also in cell culture experiments people don't take a new batch for each experimental condition. They divide the batch into groups and then repeat the experiment with another batch. Then compare the results from different batches. That is/was a bit confusing. There are different depths in an experiment, but I guess everything depends on the question you are asking. If I am interested in mouse weight, then each mouse is my sample or actually replicate. If I am interested in the cells then each experimental group with the cells becomes my sample. (I am not sure but maybe the most ideal would be treating cells from each mice with just one treatment, so that each cell population are independent from each other (like new batch of cells for each treatment). But then it would result in animal massacre and that does not make sense at all.)

Anyway in the figures 6 and 7, I say that if I take 4 mice and calculate the mean of the parameter of interest and repeat this 3 times, then the sd of these means are actually SEM estimation from single sampling. In other words if I measured the weights from 4 different mice, I can calculate the SEM via dividing sd of my measurements to square root of 4(n). If I repeated this experiment many more times, sd of the mean of each repeat would be the SEM I calculated earlier. The problem is, below I claimed that if we have replicates we can calculate the SEM by directly taking the sd of the replicate means, we don't need to estimate it since we have replicates. But I was confused about the term of "biological replicates". In theory if you are interested in the mean weight differences in different experimental conditions, each mice you use is a biological replicate. So when you compare 12 control mice to 12 treated mice you have sample size of 12. One would not repeat this experiment with more groups of 24 mice to get a mean from each of them to compare the effect of control vs treatment conditions. A different lab may repeat this experiment with 24 mice and then comparing these two experiments would be a question of reproduciblity (like meta analysis). In that case we would have sample size of 2 I think, and we would go one step deeper. So in reality we never calculate SEM from replicate standard deviations. We don't need to. If we had 12 mice we wouldn't use 6 of them to do the experiment and then use the other 6 to repeat it, we would use all 12 mice and keep our sample size high.

I also wanted to compare different ways of estimating SEM as I write this. I took samples with the size of (n=3, 10, 30) from a population (σ = 20, size = 100000). Then I calculated the sd of sampling means(SEM) with 3 different methods:

1. $\frac{\sigma}{\sqrt{n}}$

I used the population sd(σ). Which is indicated as **horizontal line**. (Expectation) 

2. $\frac{sd}{\sqrt{n}}$

I used sd of the sample as the estimate of σ. **Purple dots**

3. sd of the sampling means

I repeated the sampling process 1000 times and calculated the SEM directly via taking sd of the sampling means. **Orange dots**

The whole process was repeated 25 times showing the results I got each 25 times. 

```{r, layout="l-body-outset", fig.width=10, fig.height=3, fig.cap= "Different sample sizes and estimation of SEM via different methods"}
#In flow cytometry, I measure 50000 cells for one parameter and then take the median fluorescence intensity of that parameter. So technically 50000 cells become my "technical replicates". Then I repeat the experiment with other 2 mice and calculate median. In the end I have 3 data point, 3 replicates that I can compare.
set.seed(1)

sdPop <- function(vector, n){
  sdsam <- sqrt(sum( (vector-mean(vector))^2) / n)
  return(sdsam)
}


n1 <- rnorm(100000, mean = 160, sd = 20)

semEstimator <- function(set, setN,sampsize, replicationN= 1000){
  
      estimate <- list()
      popisd <- sdPop(set,setN)
      p <- popisd / sqrt(sampsize)
      
      for(i in 1:25){
        samp <- sample(set, sampsize)
        rep <- replicate(replicationN,mean(sample(set, sampsize)) )
        
        e <- sd(samp) / sqrt(sampsize)
        s <- sd(rep)
        
        estimate[[i]] <- c(e,s)
        
      }
      
      esti_df <- do.call(rbind.data.frame, estimate)
      colnames(esti_df) <- c("e","s")
      esti_df <- esti_df %>%
        mutate(trial = 1:nrow(esti_df)) %>%
        pivot_longer(cols = 1:2, names_to = "estimates",values_to = "SEM")
      
      plot <- esti_df %>%
        ggplot()+
        geom_point(aes(x= trial,y = SEM, color = estimates))+
        geom_hline(yintercept = p)+
        scale_color_viridis_d(begin = 0.2,end = 0.7, option = "B")+
        theme_bw()+
        theme(
          legend.position = "none"
        )+
        scale_y_continuous(breaks = 1:20, limits = c(1,20))
      
      return(plot)
}


plot_grid(
semEstimator(n1, 100000,sampsize = 3),
semEstimator(n1, 100000,sampsize = 10),
semEstimator(n1, 100000,sampsize = 30),nrow = 1,labels = list("n=3", "n=10", "n=30")
)

# low replication number
#plot_grid(
#semEstimator(n1, 100000,sampsize = 3,replicationN = 3),
#semEstimator(n1, 100000,sampsize = 10,replicationN = 3),
#semEstimator(n1, 100000,sampsize = 30,replicationN = 3),nrow = 1,labels = list("n=3", "n=10", "n=30")
#)
```

One can see that estimating SEM via $\frac{sd}{\sqrt{n}}$ is not actually that far away from the expectation especially with increasing sample size. When we do replicates it looks more accurate true, but when I did just 3 replicates that estimate was also way off(not shown). It is fun little graph. I hope I was able to explain it.   

## Intro

In the last post we bought thousands of mice to get the null distribution of the mouse weights. But we cannot do that every time can we? At this point **statistical inference** comes to the rescue, which helps us to *infer* the probability of observing certain outcome, with just from small amount of samples. It can do its magic because sometimes the values we have can be approximated with a certain distribution. Our mean weight differences, when plotted follows a normal distribution for example (red line). Thus if such a distribution is applicable to our values one can use that distribution to get an approximate probability of certain outcome. 

```{r, fig.cap= "Null distribution from last post"}
nullplot <- readRDS("../../nullplot.rds")


p1 <- ggplot()+
  geom_histogram(data = nullplot , fill = "black" , binwidth = 0.1,mapping = aes(x=null, y = ..density..))
p2 <- ggplot()+
  geom_histogram(data = nullplot , fill = "black" , binwidth = 0.1,mapping = aes(x=null, y = ..density..))+
  stat_function(data = nullplot,fun = dnorm, args = list(mean = mean(nullplot$null), sd = sd(nullplot$null)), size = 2, color= "firebrick")

plot_grid(p1,p2)
```

Ok, let's use normal distribution, but how can we adjust this distribution to fit our data? In order to define a normal distribution we need two values: **mean**(μ) and **standard deviation**(σ) of our population. (as one can see from the scary normal distribution formula)

$$
\mbox{f}(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp{\left( \frac{-(x-\mu)^2}{2 \sigma^2} \right)}
$$

## Central Limit Theorem

```{r,fig.align ='center', fig.cap= "Population and Sample Parameters", preview=TRUE}
knitr::include_graphics("images/Ps_mean.png")
```

So we need to estimate our **population mean**  $μ_X$ and **population sd** $\sigma_X$.

which we can do with our **sample mean** $\bar{X}$ and **sample sd** $s_X$, with the help of one and only Central Limit Theorem(CLT).

CLT says that when the sample size (N) is large, the average of these random samples $\bar{X}$ follow a normal distribution that has the mean of the population $μ_X$  and has a sd of $\frac{\sigma_X}{\sqrt{N}}$. 

In another words, imagine that we sample 30 people randomly and record the mean height. Then repeat this couple of times so that we have several means. Distribution of these sampling means would follow a normal distribution with the mean $μ_X$ and with sd $\frac{\sigma_X}{\sqrt{30}}$. 

Note that $\frac{\sigma_X}{\sqrt{N}}$ is also famously known as Standard Error of the Mean (SEM).

### What is SEM actually?

Standard Error of the Mean.. What a confusing name... But apparently this was not the case before. This is actually it is nick name it seems. Its full name is **"The estimated standard deviation of the sampling distribution of x-bar"** according to [this discussion](https://stats.stackexchange.com/questions/60484/why-is-the-formula-for-standard-error-the-way-it-is). Which is longer but more explanatory. As it suggests, SEM is just the standard deviation of the means($\bar{X}$) of your samples. So you took four measurements and calculated mean of it, repeated this 10 times. You get 10 means, standard deviation of these means is SEM.

<aside>
Ona sadece iş arkadaşları SEM der.


```{r,fig.align ='center', fig.cap= "Figure from: https://www.haberler.com/fotogaleri/yilan-hikayesi-nin-memoli-sinin-son-hali/"}
knitr::include_graphics("images/memoli.jpg")
```
</aside>

### Simulation with different sample sizes

Here I simulated different populations with different characteristics, each with size of 200.000, mean of μ = ~130 and sd of σ = ~34. On the left we see the different populations (bimodal, normal, uniform). I sampled from these populations with different sample sizes (n=2, 10, 30, 50), calculated the mean and repeated this process 100 times (green histograms). I also plotted two normal distributions and means. Black lines show the calculations done by using population parameters; normal distribution with sd of $\frac{\sigma_X}{\sqrt{N}}$ and mean: $μ_P$. Red lines show the empirical estimate from our sampling means; normal distribution with sd $s_X$ and mean $\bar{X}$.

<aside>
CLT 

*Ne olursan ol yine gel* 

diyen Mevlana,

*Ben insanın değerini bölemem*

*Doğu-batı, gavur-müslüm bir bana!* 

diyen Aşık Mahzuni Şerif gibi.
</aside>

Here one can see that actually even with sample size of 2 we get a quite accurate estimate of the mean and sd of the means(SEM). Although the actual mean calculations(histograms) are not completely normally distributed, it still resembles a normal distribution. As we increase the sample size we see that the distribution of the means get much more similar to the suggested normal distribution by CLT (with the mean of the population, and sd of $\frac{\sigma_X}{\sqrt{N}}$). 

Another thing that we can notice is that SEM decreases as we increase the sample size. We get much more accurate estimate of the real population mean with high N.

Lastly we have seen that CLT did not care about the population distribution too much. In the end we got normally distributed means.


```{r, layout="l-body-outset", fig.width=12, fig.height=6, fig.cap= "Sample size differences illustration"}
set.seed(1)

# I tried to look at deviation of sd when you take one replicate of sample size 30 vs 30 replicate of sample size 30. I wanted to see if our sd estimate varies differently. Like Standard error of standard error. 

#ankara_height <- rnorm(5000000, mean = 160, sd = 20)
#
#hist(ankara_height)
#
#vsd <-c()
#for(i in 1:100){
#  sankara <- replicate(mean(sample(ankara_height, 30)), n = 30)
#  vsd <- c(vsd,sd(sankara))
#}
#head(vsd)
#hist(vsd)
#
#sdPop(ankara_height, 5000000)
#
#vsd2 <-c()
#for(i in 1:100){
#  sankara <- replicate(sample(ankara_height, 30), n = 1)
#  vsd2 <- c(vsd2,sd(sankara))
#}
#head(vsd2)
#
#vsd2 <- vsd2/sqrt(30)
#
#sd(vsd)
#sd(vsd2)
#mean(vsd)
#mean(vsd2)
#mean(ankara_height)
#sd(ankara_height)/sqrt(30)
#




sdPop <- function(vector, n){
  sdsam <- sqrt(sum( (vector-mean(vector))^2) / n)
  return(sdsam)
}


n1 <- rnorm(100000, mean = 160, sd = 20)
n2 <- rnorm(100000, mean = 100, sd = 10)

bimod <- c(n1, n2)



#
#mean(bimod)
#sd(bimod)
#hist(bimod)

normd <- rnorm(200000, mean = 130, sd = 34)

#hist(normd)

uni <- runif(200000, 71,189)
#mean(uni)
#sd(uni)

datadists <- data.frame(bimod = bimod, normd = normd, uniform = uni)

datadists <- datadists %>%
  pivot_longer(cols = 1:3, names_to = "dist")

pd <- ggplot(datadists)+
  geom_histogram(aes(value, y = ..density..), bins = 113, fill =  "#f54876")+
  facet_grid(dist~.)+
  coord_cartesian(xlim = c(0,250))+
  theme_bw()+
  theme(
  strip.background = element_blank(),
  strip.text.y = element_blank()
)+
  ggtitle("Population Distributions")

datadistsSample <- datadists %>% 
  group_by(dist) %>%
  summarize(N2 = replicate(mean(sample(value, size = 2)),n = 100),
            N10 = replicate(mean(sample(value, size = 10)),n = 100),
            N30 = replicate(mean(sample(value, size = 30)),n = 100),
            N50 = replicate(mean(sample(value, size = 50)),n = 100))

datadistsSampleStat <- datadistsSample %>%
  summarise(meanN2 = mean(N2),
            meanN10 = mean(N10),
            meanN30 = mean(N30),
            meanN50 = mean(N50),
            sdN2 = sd(N2) ,
            sdN10 = sd(N10),
            sdN30 = sd(N30),
            sdN50 = sd(N50))


grid <- with(datadistsSample, seq(min(N2), max(N2), length = 100))
normaldens2 <- ddply(datadistsSample, "dist", function(datadistsSample) {
  data.frame( 
    N2 = grid,
    density = dnorm(grid, mean(datadistsSample$N2), sd(datadistsSample$N2) )
  )
})

grid <- with(datadistsSample, seq(min(N10), max(N10), length = 100))
normaldens10 <- ddply(datadistsSample, "dist", function(datadistsSample) {
  data.frame( 
    N10 = grid,
    density = dnorm(grid, mean(datadistsSample$N10),  sd(datadistsSample$N10) )
  )
})

grid <- with(datadistsSample, seq(min(N30), max(N30), length = 100))
normaldens30 <- ddply(datadistsSample, "dist", function(datadistsSample) {
  data.frame( 
    N30 = grid,
    density = dnorm(grid, mean(datadistsSample$N30),  sd(datadistsSample$N30) )
  )
})
grid <- with(datadistsSample, seq(min(N50), max(N50), length = 100))
normaldens50 <- ddply(datadistsSample, "dist", function(datadistsSample) {
  data.frame( 
    N50 = grid,
    density = dnorm(grid, mean(datadistsSample$N50),  sd(datadistsSample$N50) )
  )
})


p2 <- ggplot(data = datadistsSample, mapping = aes(x = N2))  + 
  geom_histogram(bins = 15, aes(y =  ..density..), fill = "#02a890") + 
  geom_line(mapping = aes(y = density), data = normaldens2, colour = "firebrick", size = 1.5) +
  facet_grid(dist~.)+
  geom_vline(data = datadistsSampleStat, aes(xintercept =meanN2), color = "firebrick")+
  geom_vline(data = datadistsSampleStat, aes(xintercept =130), color = "black")+
  stat_function(fun = dnorm, args = list(mean = 130, sd = 34 /sqrt(2)),  size = 1.5)+
  theme_bw()+
  theme(
  strip.background = element_blank(),
  strip.text.y = element_blank()
)+
  ylab("")+
  ggtitle("N = 2")+
  coord_cartesian(xlim = c(70,190))


p10 <- ggplot(data = datadistsSample, mapping = aes(x = N10))  + 
  geom_histogram(bins = 15, aes(y =  ..density..), fill = "#02a890") + 
  geom_line(mapping = aes(y = density), data = normaldens10, colour = "firebrick",  size = 1.5) +
  facet_grid(dist~.)+
  geom_vline(data = datadistsSampleStat, aes(xintercept =meanN10), color = "firebrick")+
  geom_vline(data = datadistsSampleStat, aes(xintercept =130), color = "black")+
  stat_function(fun = dnorm, args = list(mean = 130, sd = 34 /sqrt(10)),  size = 1.5)+
  theme_bw()+
  theme(
  strip.background = element_blank(),
  strip.text.y = element_blank()
)+
  ylab("")+
  ggtitle("N = 10")+
  coord_cartesian(xlim = c(70,190))


p30 <- ggplot(data = datadistsSample, mapping = aes(x = N30))  + 
  geom_histogram(bins = 15, aes(y =  ..density..), fill = "#02a890") + 
  geom_line(mapping = aes(y = density), data = normaldens30, colour = "firebrick",  size = 1.5) +
  facet_grid(dist~.)+
  geom_vline(data = datadistsSampleStat, aes(xintercept =meanN30), color = "firebrick")+
  geom_vline(data = datadistsSampleStat, aes(xintercept =130), color = "black")+
  stat_function(fun = dnorm, args = list(mean = 130, sd = 34 /sqrt(30)),  size = 1.5)+
  theme_bw()+
  theme(
  strip.background = element_blank(),
  strip.text.y = element_blank()
)+
  ylab("")+
  ggtitle("N = 30")+
  coord_cartesian(xlim = c(70,190))


p50 <- ggplot(data = datadistsSample, mapping = aes(x = N50))  + 
  geom_histogram(bins = 15, aes(y =  ..density..), fill = "#02a890") + 
  geom_line(mapping = aes(y = density), data = normaldens50, colour = "firebrick",  size = 1.5) +
  facet_grid(dist~.)+
  geom_vline(data = datadistsSampleStat, aes(xintercept =meanN50), color = "firebrick")+
  geom_vline(data = datadistsSampleStat, aes(xintercept =130), color = "black")+
  stat_function(fun = dnorm, args = list(mean = 130, sd = 34 /sqrt(50)),  size = 1.5)+
  theme_bw()+
  ylab("")+
  ggtitle("N = 50")+
  coord_cartesian(xlim = c(70,190))


plot_grid(pd,p2,p10,p30,p50, nrow = 1)

```


I would like to touch on a few points which always confused me. I think I finally got it. :)

### Sample size vs Replicates

I think sometimes it gets quite confusing to understand what the sample size is, at least for me.. If we look at the following figure, on the left side I took 4 samples. Let's say I took 4 mice and measured their weight and that is it. In this case I have a sample size of 4 and I only performed 1 trial/replicate. On the right side I took 4 mice again but repeated this 5 times in total. Here my sample size is 4 again and I just replicated it 5 times.

On the right bottom I also illustrated that as we do more replicates we would expect these sampling means from each replicate to form a normal distribution. Higher our sample size is, more it resembles a normal distribution according to CLT. In statistics they say minimum sample size should be 30 as a rule of thumb, but as we also seen in the simulation, sample size of 10 was also reasonably good. As far as I read this rule of thumb depends mostly on the distribution of the population. **Some confusing addition to this topic:** Furthermore, as we do a statistic test we divide mean differences with estimated standard deviation. With this additional division, sample size starts to matter more apparently [@dals]. See the [next post](https://bstats.netlify.app/posts/2021-11-27-inference/) about this.

```{r, layout="l-body-outset", fig.width=8, fig.height=7,fig.align='center', fig.cap= "Sampling"}
knitr::include_graphics("images/Sampling.png")


## so when one measures 12 mice. you have no replicates but 12 samples. you can estimate SEM via sd of this sample / sqrt(12)
## when one measures 12 mice 3 times, one can take the means and calculate the sd of the means directly which gives the estimate for SEM

## In both cases one has same sample size. What does having replicates bring?
## For example if I replicate my experiment with multiple mice it then allows me to conclude about this mice strain.
## If I dont replicate I can only conclude about that mouse.

```
### How to calculate SEM in practice?

The thing that confused me a lot is how to calculate the SEM in practice, especially when you have or don't have replicates. In the next figure, on the left we measured weights of 4 mice again. According to $SEM = \frac{\sigma_X}{\sqrt{N}}$ we can get SEM. But since we don't have data from billions of mice that live in the world, we don't know the population standard deviation (σ). Good thing is we have sample sd ($s_X$) that we can use as estimate of σ. Sample standard deviation is calculated a little bit differently than population sd:  
$$s_X = \sqrt{\frac{(X_i - \bar{X})^2 }{N - 1}}$$ 
We use sample mean and at denominator we have N-1 instead of N. This is simply because, when we estimate σ from sample sd we tend to underestimate it. Thus we boost it up by dividing with a smaller number. There is also a more logical explanations about this, which I can discuss later.

So we can calculate the $s_X$ with this formula and calculate the estimate for SEM via $SEM = \frac{s_X}{\sqrt{N}}$.

**Take the following paragraph and figure with caution. See the notes at the beginning of the post**

What if we have replicates? Then we already calculate mean for each replicate, thus we have more than one mean estimate. Thus one can directly calculate the sd of these means as usual to get the SEM. Which makes sense I think and also according to [this resource](https://sisu.ut.ee/measurement/33-standard-deviation-mean). THUS, as far as I understood when you have replicates you don't have to do this $\frac{s_X}{\sqrt{N}}$ to get SEM (And I don't know what to write to the place of $s_X$ to be honest when you have replicates). 

```{r, layout="l-body-outset", fig.width=8, fig.height=7,fig.align='center', fig.cap= "Calculation of SEM"}
knitr::include_graphics("images/Sampling2.png")
```


